{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "graphic-reader",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hydraulic-future",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /afs/inf.ed.ac.uk/user/s21/s2125219/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from joblib import Memory\n",
    "\n",
    "from classes.metrics import Metrics\n",
    "from classes.classification_pipeline import ClassificationPipeline\n",
    "from classes.data_loader import DataLoader, Encoder\n",
    "from classes.preprocessing import Preprocessor\n",
    "from utils.helpers import pos_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-working",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "established-trailer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 3446/239073 [00:00<00:06, 34447.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239073/239073 [00:05<00:00, 42815.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplicating...\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = DataLoader().create_dataframe(preprocess=True, split=True, remove_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "removable-arizona",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>phrase</th>\n",
       "      <th>phrase_clean</th>\n",
       "      <th>sentiment_val</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94640</th>\n",
       "      <td>229789</td>\n",
       "      <td>certainly ranks as the most original in years .</td>\n",
       "      <td>certainly ranks original years .</td>\n",
       "      <td>0.79167</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54712</th>\n",
       "      <td>47301</td>\n",
       "      <td>The whole is quite entertaining , but despite ...</td>\n",
       "      <td>The whole quite entertaining despite virtues u...</td>\n",
       "      <td>0.47222</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211918</th>\n",
       "      <td>11902</td>\n",
       "      <td>the story 's pathetic</td>\n",
       "      <td>story pathetic</td>\n",
       "      <td>0.16667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56047</th>\n",
       "      <td>70261</td>\n",
       "      <td>This is pure , exciting moviemaking .</td>\n",
       "      <td>This pure exciting moviemaking .</td>\n",
       "      <td>0.91667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Very positive</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81973</th>\n",
       "      <td>154034</td>\n",
       "      <td>artistically '</td>\n",
       "      <td>artistically</td>\n",
       "      <td>0.51389</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        phrase_id                                             phrase  \\\n",
       "94640      229789    certainly ranks as the most original in years .   \n",
       "54712       47301  The whole is quite entertaining , but despite ...   \n",
       "211918      11902                              the story 's pathetic   \n",
       "56047       70261              This is pure , exciting moviemaking .   \n",
       "81973      154034                                     artistically '   \n",
       "\n",
       "                                             phrase_clean  sentiment_val  \\\n",
       "94640                    certainly ranks original years .        0.79167   \n",
       "54712   The whole quite entertaining despite virtues u...        0.47222   \n",
       "211918                                     story pathetic        0.16667   \n",
       "56047                    This pure exciting moviemaking .        0.91667   \n",
       "81973                                        artistically        0.51389   \n",
       "\n",
       "        label_id          label  word_count  \n",
       "94640        4.0       Positive           5  \n",
       "54712        3.0        Neutral          10  \n",
       "211918       1.0  Very negative           2  \n",
       "56047        5.0  Very positive           5  \n",
       "81973        3.0        Neutral           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ambient-transmission",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126124, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-truth",
   "metadata": {},
   "source": [
    "# Train, test, dev split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bored-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['phrase_clean'], train['label_id']\n",
    "X_val, y_val = validate['phrase_clean'], validate['label_id']\n",
    "X_test, y_test = test['phrase_clean'], test['label_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-scholarship",
   "metadata": {},
   "source": [
    "# Feature Engineering & Selection\n",
    "\n",
    "- Features to include:\n",
    "\n",
    "    - phrase length\n",
    "    - punctuation count\n",
    "    - capital letters count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "demonstrated-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_count = lambda l1, l2: sum([1 for x in l1 if x in l2])\n",
    "caps_count = lambda l1: sum([1 for x in l1 if x.isupper()])\n",
    "\n",
    "def get_phrase_length(text):\n",
    "    return np.array([len(t) for t in tqdm(text)]).reshape(-1, 1)\n",
    "\n",
    "def get_num_punct(text):\n",
    "    return np.array([punct_count(t, set(string.punctuation)) for t in tqdm(text)]).reshape(-1, 1)\n",
    "\n",
    "def get_num_caps(text):\n",
    "    return np.array([caps_count(t) for t in tqdm(text)]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extended-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word', \n",
    "                             max_features=10000, \n",
    "                             use_idf=True, \n",
    "                             ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-nowhere",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "champion-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "features = FeatureUnion([\n",
    "    ('phrase_length', Pipeline([\n",
    "        ('f1', FunctionTransformer(get_phrase_length, validate=False))]\n",
    "    )),\n",
    "])\n",
    "\n",
    "feature_processing = Pipeline([('features', features)])\n",
    "\n",
    "# Classifiers\n",
    "dc = ClassificationPipeline(clf_id='dc', \n",
    "                            clf=DummyClassifier(strategy='most_frequent'),\n",
    "                            vectorizer=tfidf_vect,\n",
    "                            feature_processing=feature_processing)\n",
    "gnb = ClassificationPipeline(clf_id='gnb',\n",
    "                            clf=GaussianNB(),\n",
    "                            vectorizer=tfidf_vect,\n",
    "                            feature_processing=feature_processing)\n",
    "lr = ClassificationPipeline(clf_id='lr', \n",
    "                           clf=LogisticRegression(max_iter=10000),\n",
    "                           vectorizer=tfidf_vect,\n",
    "                           feature_processing=feature_processing)\n",
    "lin_svm = ClassificationPipeline(clf_id='lin_svm', \n",
    "                                 clf=LinearSVC(),\n",
    "                                 vectorizer=tfidf_vect,\n",
    "                                 feature_processing=feature_processing)\n",
    "rbf_svm = ClassificationPipeline(clf_id='rbf_svm', \n",
    "                                 clf=SVC(kernel='rbf'), \n",
    "                                 vectorizer=tfidf_vect,\n",
    "                                 feature_processing=feature_processing)\n",
    "rf = ClassificationPipeline(clf_id='rf', \n",
    "                            clf=RandomForestClassifier(max_depth=10, n_estimators=50), \n",
    "                            vectorizer=tfidf_vect,\n",
    "                            feature_processing=feature_processing)\n",
    "mlp = ClassificationPipeline(clf_id='mlp', \n",
    "                             clf=MLPClassifier(max_iter=800),\n",
    "                             vectorizer=tfidf_vect,\n",
    "                             feature_processing=feature_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "healthy-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate classifiers using additional features\n",
    "clfs = [dc, gnb, lr, lin_svm, rbf_svm, rf, mlp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-watch",
   "metadata": {},
   "source": [
    "# Train classifiers using additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s21/s2125219/miniconda3/envs/dme/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: The 'cachedir' parameter has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "You provided \"cachedir='/tmp/tmpce45votn'\", use \"location='/tmp/tmpce45votn'\" instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dc...\n",
      "\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(FeatureUnion(transformer_list=[('text',\n",
      "                                Pipeline(steps=[('vectorizer',\n",
      "                                                 TfidfVectorizer(max_features=10000,\n",
      "                                                                 ngram_range=(1,\n",
      "                                                                              3))),\n",
      "                                                ('to_dense',\n",
      "                                                 <classes.dense_transformer.DenseTransformer object at 0x7fcd09577110>),\n",
      "                                                ('lda',\n",
      "                                                 LinearDiscriminantAnalysis(n_components=4))])),\n",
      "                               ('feature_processing',\n",
      "                                Pipeline(steps=[('features',\n",
      "                                                 FeatureUnion(transformer_list=[('phrase_length',\n",
      "                                                                                 Pipeline(steps=[('f1',\n",
      "                                                                                                  FunctionTransformer(func=<function get_phrase_length at 0x7fcd09e18680>))]))]))]))]), \n",
      "94640                      certainly ranks original years .\n",
      "54712     The whole quite entertaining despite virtues u...\n",
      "211918                                       story pathetic\n",
      "56047                      This pure exciting moviemaking .\n",
      "81973                                          artistically\n",
      "                                ...                        \n",
      "101825                                     delightful minor\n",
      "233666                                        probably like\n",
      "99511                                      courtroom dramas\n",
      "193398                                               sticks\n",
      "132787                                            community\n",
      "Name: phrase_clean, Length: 126124, dtype: object, \n",
      "94640     4.0\n",
      "54712     3.0\n",
      "211918    1.0\n",
      "56047     5.0\n",
      "81973     3.0\n",
      "         ... \n",
      "101825    4.0\n",
      "233666    3.0\n",
      "99511     3.0\n",
      "193398    3.0\n",
      "132787    3.0\n",
      "Name: label_id, Length: 126124, dtype: float64, \n",
      "None, message_clsname='Pipeline', message=None)\n",
      "Making dense transformation...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cachedir = mkdtemp()\n",
    "memory = Memory(cachedir=cachedir, verbose=10)\n",
    "\n",
    "results = defaultdict(Metrics)\n",
    "\n",
    "for clf in clfs:\n",
    "    print(f'Training {clf.clf_id}...\\n')\n",
    "    \n",
    "    accuracy, precision, recall, f1, kappa = clf.train_and_evaluate(X_train, y_train, X_val, y_val, \n",
    "                                                          use_features=True, memory=memory)\n",
    "    \n",
    "    results[clf.clf_id].accuracy = accuracy \n",
    "    results[clf.clf_id].precision = precision\n",
    "    results[clf.clf_id].recall = recall\n",
    "    results[clf.clf_id].f1 = f1\n",
    "    results[clf.clf_id].kappa = kappa\n",
    "    \n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-search",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k, v in json.loads(Encoder().encode(results)).items():\n",
    "    accuracy = v['accuracy']\n",
    "    precision = v['precision']\n",
    "    recall = v['recall']\n",
    "    f1 = v['f1']\n",
    "    kappa = v['kappa']\n",
    "    \n",
    "    print(f'{k} --- Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}, Kappa: {kappa:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-trading",
   "metadata": {},
   "source": [
    "# Train classifiers without using additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaulate classifiers without additional features\n",
    "cachedir = mkdtemp()\n",
    "memory = Memory(cachedir=cachedir, verbose=10)\n",
    "\n",
    "results = defaultdict(Metrics)\n",
    "\n",
    "for clf in clfs:\n",
    "    print(f'Training {clf.clf_id}...\\n')\n",
    "    \n",
    "    accuracy, precision, recall, f1, kappa = clf.train_and_evaluate(X_train, y_train, X_val, y_val, \n",
    "                                                          use_features=True, memory=memory)\n",
    "    \n",
    "    print(f'{clf.clf_id} --- Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1}, Kappa: {kappa}')\n",
    "    \n",
    "    results[clf.clf_id].accuracy = accuracy \n",
    "    results[clf.clf_id].precision = precision\n",
    "    results[clf.clf_id].recall = recall\n",
    "    results[clf.clf_id].f1 = f1\n",
    "    results[clf.clf_id].kappa = kappa\n",
    "    \n",
    "\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in json.loads(Encoder().encode(results)).items():\n",
    "    accuracy = v['accuracy']\n",
    "    precision = v['precision']\n",
    "    recall = v['recall']\n",
    "    f1 = v['f1']\n",
    "    kappa = v['kappa']\n",
    "    \n",
    "    print(f'{k} --- Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}, Kappa: {kappa:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-eleven",
   "metadata": {},
   "source": [
    "# Best performing classifier on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-beach",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dedup validation set to avoid adding any bias\n",
    "validate = DataLoader().dedup(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = validate['phrase_clean'], validate['label_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train, X_val])\n",
    "y = pd.concat([y_train, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-estonia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cachedir = mkdtemp()\n",
    "memory = Memory(cachedir=cachedir, verbose=10)\n",
    "\n",
    "accuracy, precision, recall, f1, kappa = rf.train_and_evaluate(X, y, \n",
    "                                                                X_test, y_test, \n",
    "                                                                use_features=True, \n",
    "                                                                memory=memory)\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1, kappa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
